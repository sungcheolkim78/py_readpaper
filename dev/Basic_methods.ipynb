{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# py_readpaper\n",
    "\n",
    "## Goal\n",
    "\n",
    "논문을 읽어 들여서 meta 정보를 확인하고 필요하다면 exif 정보로 저장하고 또한 abstact, title 들을 추출한다. \n",
    "\n",
    "## Basic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_readpaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004-Kaji-Analytical_Chemistry.pdf  2017-Golmohammadi-arXiv.pdf\r\n",
      "2004-Kaji-Analytical_Chemistry.txt  2017-Golmohammadi-arXiv.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls ../example/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... read from exif doi\n",
      "self: None\n",
      "exif: ['big data', 'deep learning analysis', 'seizure detection']\n",
      "text: None\n"
     ]
    }
   ],
   "source": [
    "p = py_readpaper.Paper('../example/2017-Golmohammadi-arXiv.pdf', debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "- Filename: ../example/2017-Golmohammadi-arXiv.pdf\n",
       "- Title: Deep Architectures for Automated Seizure Detection in Scalp EEGs\n",
       "- Author: Meysam Golmohammadi and Saeedeh Ziyabari and Vinit Shah and Silvia Lopez de Diego and Iyad Obeid and Joseph Picone\n",
       "- Year: 2017\n",
       "- DOI: arXiv:1712.09776\n",
       "- Journal: arXiv\n",
       "- Keywords: ['big data', 'deep learning analysis', 'seizure detection']\n",
       "- Abstract: Automated seizure detection using clinical electroencephalograms is a challenging machine learning problem because the multichannel signal often has an extremely low signal to noise ratio. Events of interest such as seizures are easily confused with signal artifacts (e.g, eye movements) or benign variants (e.g., slowing). Commercially available systems suffer from unacceptably high false alarm rates. Deep learning algorithms that employ high dimensional models have not previously been effective due to the lack of big data resources. In this paper, we use the TUH EEG Seizure Corpus to evaluate a variety of hybrid deep structures including Convolutional Neural Networks and Long Short-Term Memory Networks. We introduce a novel recurrent convolutional architecture that delivers 30% sensitivity at 7 false alarms per 24 hours. We have also evaluated our system on a held-out evaluation set based on the Duke University Seizure Corpus and demonstrate that performance trends are similar to the TUH EEG Seizure Corpus. This is a significant finding because the Duke corpus was collected with different instrumentation and at different hospitals. Our work shows that deep learning architectures that integrate spatial and temporal contexts are critical to achieving state of the art performance and will enable a new generation of clinically-acceptable technology."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will you change [Abstract] from\n",
      "\n",
      "Automated seizure detection using clinical electroencephalograms is a challenging machine learning problem because the multichannel signal often has an extremely low signal to noise ratio. Events of interest such as seizures are easily confused with signal artifacts (e.g, eye movements) or benign variants (e.g., slowing). Commercially available systems suffer from unacceptably high false alarm rates. Deep learning algorithms that employ high dimensional models have not previously been effective due to the lack of big data resources. In this paper, we use the TUH EEG Seizure Corpus to evaluate a variety of hybrid deep structures including Convolutional Neural Networks and Long Short-Term Memory Networks. We introduce a novel recurrent convolutional architecture that delivers 30% sensitivity at 7 false alarms per 24 hours. We have also evaluated our system on a held-out evaluation set based on the Duke University Seizure Corpus and demonstrate that performance trends are similar to the TUH EEG Seizure Corpus. This is a significant finding because the Duke corpus was collected with different instrumentation and at different hospitals. Our work shows that deep learning architectures that integrate spatial and temporal contexts are critical to achieving state of the art performance and will enable a new generation of clinically-acceptable technology.\n",
      "\n",
      "tohelp\n",
      "\n",
      "(Yes/No)n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Automated seizure detection using clinical electroencephalograms is a challenging machine learning problem because the multichannel signal often has an extremely low signal to noise ratio. Events of interest such as seizures are easily confused with signal artifacts (e.g, eye movements) or benign variants (e.g., slowing). Commercially available systems suffer from unacceptably high false alarm rates. Deep learning algorithms that employ high dimensional models have not previously been effective due to the lack of big data resources. In this paper, we use the TUH EEG Seizure Corpus to evaluate a variety of hybrid deep structures including Convolutional Neural Networks and Long Short-Term Memory Networks. We introduce a novel recurrent convolutional architecture that delivers 30% sensitivity at 7 false alarms per 24 hours. We have also evaluated our system on a held-out evaluation set based on the Duke University Seizure Corpus and demonstrate that performance trends are similar to the TUH EEG Seizure Corpus. This is a significant finding because the Duke corpus was collected with different instrumentation and at different hospitals. Our work shows that deep learning architectures that integrate spatial and temporal contexts are critical to achieving state of the art performance and will enable a new generation of clinically-acceptable technology.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#abstract = \"We have established the nanofabrication technique for constructing nanopillars with high aspect ratio (100-500 nm diameter and 500-5000 nm tall) inside a microchannel on a quartz chip. The size of pillars and the spacing between pillars are designed as a DNA sieving matrix for optimal analysis of large DNA fragments over a few kilobase pairs (kbp). A chip with nanopillar channel and simple cross injector was developed based on the optimal design and applied to the separation of DNA fragments (1-38 kbp) and large DNA fragments (λ DNA, 48.5 kbp; T4 DNA, 165.6 kbp) that are difficult to separate on conventional gel electrophoresis and capillary electrophoresis without a pulsed-field technique. DNA fragments ranging from 1 to 38 kbp were separated as clear bands, and furthermore, the mixture of λ DNA and T4 DNA was successfully separated by a 380-μm-long nanopillar channel within only 10s even under a direct current (dc) electric field. Theoretical plate number N of the channel (380-1450 μm long) was 1000-3000 (0.7×106 - 2.1×106 plates/m). A single DNA molecule observation during electrophoresis in a nanopillar channel revealed that the optimal nanopillars induced T4 DNA to form a narrow U-shaped conformation during electrophoresis whereas λ DNA kept a rather spherical conformation. We demonstrated that, even under a dc electric field, the optimal nanopillar dimensions depend on a gyration radius of DNA molecule that made it possible to separate large DNA fragments in a short time.\"\n",
    "\n",
    "#p._abstract = abstract\n",
    "p.abstract(\"help\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['layers',\n",
       " 'modeling',\n",
       " 'data',\n",
       " 'approach',\n",
       " 'features',\n",
       " 'learn',\n",
       " 'eeg',\n",
       " 'seizures',\n",
       " 'train',\n",
       " 'based',\n",
       " 'analysis',\n",
       " 'times',\n",
       " 'memory',\n",
       " 'detection',\n",
       " 'network']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.keywords_gensim(p.contents(maxpages=4, clean=True), words=15)\n",
    "#p.keywords(kws=['seizure detection', 'big data', 'deep learning analysis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nonlinear techniques schad et al 2008 despite much research progress commercially available automated eeg analysis systems',\n",
       " 'applied including time – frequency analysis methods gotman et al 1982',\n",
       " 'employed modern machine learning approaches alotaiby et al 2014 deep learning algorithms',\n",
       " 'signal artifacts eg eye movements slowing commercially available systems suffer',\n",
       " 'high false detection rates ramgopal 2014 servicing false alarms',\n",
       " 'unacceptably high false alarm rates deep learning algorithms',\n",
       " 'rater agreement ira swisher et al 2015',\n",
       " 'signal event detection harati et al 2016',\n",
       " 'abnormal detection lopez et al 2015 like',\n",
       " 'scalp eegs abstract variants detection automated clinical electroencephalograms',\n",
       " 'significant resource golmohammadi et al 2017 known',\n",
       " 'hybrid deep structures including convolutional neural networks',\n",
       " '7 false alarms per 24 hours',\n",
       " 'ignored christensen et al 2014',\n",
       " 'picone 2017 however manual analysis']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.keywords_rake_nltk(p.contents(maxpages=1, split=False, clean=True), words=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... set_meta tag Author: values are same\n",
      "... set_meta tag DOI: values are same\n",
      "... set_meta tag Title: values are same\n",
      "... set_meta tag Description: values are same\n",
      "Set [Keywords] as [['big data', 'deep learning analysis', 'seizure detection']]\n"
     ]
    }
   ],
   "source": [
    "p.update_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': '1712.09776v1.pdf',\n",
       " 'url': 'http://arxiv.org/abs/1712.09776v1',\n",
       " 'month': 'Dec',\n",
       " 'year': '2017',\n",
       " 'abstract': 'Automated seizure detection using clinical electroencephalograms is a challenging machine learning problem because the multichannel signal often has an extremely low signal to noise ratio. Events of interest such as seizures are easily confused with signal artifacts (e.g, eye movements) or benign variants (e.g., slowing). Commercially available systems suffer from unacceptably high false alarm rates. Deep learning algorithms that employ high dimensional models have not previously been effective due to the lack of big data resources. In this paper, we use the TUH EEG Seizure Corpus to evaluate a variety of hybrid deep structures including Convolutional Neural Networks and Long Short-Term Memory Networks. We introduce a novel recurrent convolutional architecture that delivers 30% sensitivity at 7 false alarms per 24 hours. We have also evaluated our system on a held-out evaluation set based on the Duke University Seizure Corpus and demonstrate that performance trends are similar to the TUH EEG Seizure Corpus. This is a significant finding because the Duke corpus was collected with different instrumentation and at different hospitals. Our work shows that deep learning architectures that integrate spatial and temporal contexts are critical to achieving state of the art performance and will enable a new generation of clinically-acceptable technology.',\n",
       " 'primaryclass': 'cs.LG',\n",
       " 'archiveprefix': 'arXiv',\n",
       " 'eprint': '1712.09776v1',\n",
       " 'title': 'Deep Architectures for Automated Seizure Detection in Scalp EEGs',\n",
       " 'author': 'Meysam Golmohammadi and Saeedeh Ziyabari and Vinit Shah and Silvia Lopez de Diego and Iyad Obeid and Joseph Picone',\n",
       " 'ENTRYTYPE': 'article',\n",
       " 'ID': '1712.09776v1'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.bibtex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract contexts and abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Architectures for Automated Seizure Detection in Scalp EEGs\n",
      "Automated seizure detection using clinical electroencephalograms is a challenging machine learning problem because the multichannel signal often has an extremely low signal to noise ratio. Events of interest such as seizures are easily confused with signal artifacts (e.g, eye movements) or benign variants (e.g., slowing). Commercially available systems suffer from unacceptably high false alarm rates. Deep learning algorithms that employ high dimensional models have not previously been effective due to the lack of big data resources. In this paper, we use the TUH EEG Seizure Corpus to evaluate a variety of hybrid deep structures including Convolutional Neural Networks and Long Short-Term Memory Networks. We introduce a novel recurrent convolutional architecture that delivers 30% sensitivity at 7 false alarms per 24 hours. We have also evaluated our system on a held-out evaluation set based on the Duke University Seizure Corpus and demonstrate that performance trends are similar to the TUH EEG Seizure Corpus. This is a significant finding because the Duke corpus was collected with different instrumentation and at different hospitals. Our work shows that deep learning architectures that integrate spatial and temporal contexts are critical to achieving state of the art performance and will enable a new generation of clinically-acceptable technology.\n",
      "Introduction\n",
      "Electroencephalograms (EEGs) are used in a wide range of clinical settings to record electrical activity along the scalp. Scalp EEGs are the primary means by which physicians diagnose brain-related illnesses such as epilepsy and seizures (Obeid and Picone 2017). However, manual analysis of EEG signals requires a highly trained boardcertified neurophysiologist, and is a process that is known to have relatively low inter-rater agreement (IRA) (Swisher et al. 2015). It is a time-consuming and expensive process since the volume and velocity of the data far exceeds the available resources for detailed interpretation in real time. Automated analysis can improve the quality of patient care\n",
      "by reducing manual error and latency. In this paper, we focus on the specific problem of seizure detection, though the work presented here is also applicable to other EEG problems such as signal event detection (Harati et al. 2016) and abnormal detection (Lopez et al. 2015).\n",
      "Like most machine learning problems of this nature, many algorithms have been applied including time– frequency analysis methods (Gotman et al. 1982) and nonlinear techniques (Schad et al. 2008). Despite much research progress, commercially available automated EEG analysis systems are impractical due to high false detection rates (Ramgopal 2014). Servicing false alarms in critical care settings places too much of a cognitive burden on caregivers, and hence, the outputs from these systems are ignored (Christensen et al. 2014). This creates quality of healthcare issues as well as cost and efficiency challenges.\n",
      "Although contemporary approaches for automatic interpretation of EEGs have employed modern machine learning approaches (Alotaiby et al. 2014), deep learning algorithms that employ high dimensional models have not previously been utilized because there has been a lack of big data resources. A significant resource (Golmohammadi et al. 2017), known as the TUH EEG Seizure Corpus (TUSZ), has recently become available for EEG interpretation creating a unique opportunity to advance technology.\n",
      "The goal of this work is to demonstrate that advanced deep learning approaches that have been successful in tasks like image processing and speech recognition, where ample amounts of annotated training data are available, can be applied to EEG interpretation. To achieve this goal, we evaluated several on a standard seizure detection task. We propose a novel deep learning architecture that reduces the false alarm rate while maintaining sensitivity and specificity. We demonstrate that the performance of this system is now approaching clinical acceptance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p.contents(maxpages=1, split=False, clean=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Architectures for  \n",
      "Automated Seizure Detection in Scalp EEGs  \n",
      "Abstract \n",
      "variants \n",
      "detection \n",
      "Automated \n",
      "clinical \n",
      "electroencephalograms  is  a  challenging  machine  learning \n",
      "problem  because  the  multichannel  signal  often  has  an \n",
      "extremely low signal to noise ratio Events of interest such as \n",
      "seizures  are  easily  confused  with  signal  artifacts  eg  eye \n",
      "movements \n",
      "slowing \n",
      "Commercially  available  systems  suffer  from  unacceptably \n",
      "high false alarm rates Deep learning algorithms that employ \n",
      "high dimensional models have not previously been effective \n",
      "due to the lack of big data resources In this paper we use the \n",
      "TUH  EEG  Seizure  Corpus  to  evaluate  a  variety  of  hybrid \n",
      "deep  structures  including  Convolutional  Neural  Networks \n",
      "and  Long  Short-Term  Memory  Networks  We  introduce  a \n",
      "novel recurrent convolutional architecture that delivers 30 \n",
      "sensitivity  at  7  false  alarms  per  24  hours  We  have  also \n",
      "evaluated our system on a held-out evaluation set based on \n",
      "the  Duke  University  Seizure  Corpus  and  demonstrate  that \n",
      "performance  trends  are  similar  to  the  TUH  EEG  Seizure \n",
      "Corpus This is a significant finding because the Duke corpus \n",
      "was collected with different instrumentation and at different \n",
      "hospitals Our work shows that deep learning architectures \n",
      "that  integrate  spatial  and  temporal  contexts  are  critical  to \n",
      "achieving state of the art performance and will enable a new \n",
      "generation of clinically-acceptable technology \n",
      " Introduction   \n",
      "Electroencephalograms EEGs are used in a wide range of \n",
      "clinical settings to record electrical activity along the scalp \n",
      "Scalp  EEGs  are  the  primary  means  by  which  physicians \n",
      "diagnose  brain-related  illnesses  such  as  epilepsy  and \n",
      "seizures Obeid  and  Picone  2017  However  manual \n",
      "analysis  of  EEG  signals  requires  a  highly  trained  board-\n",
      "certified neurophysiologist and is a process that is known to \n",
      "have relatively low inter-rater agreement IRA Swisher et \n",
      "al  2015  It  is  a  time-consuming  and  expensive  process \n",
      "since the volume and velocity of the data  far exceeds the \n",
      "available resources for detailed interpretation in real time \n",
      "Automated analysis can improve the quality of patient care \n",
      "                                                 \n",
      "by  reducing  manual  error  and  latency  In  this  paper  we \n",
      "focus on the specific problem of seizure detection though \n",
      "the  work  presented  here  is  also  applicable  to  other  EEG \n",
      "problems such as signal event detection Harati et al 2016 \n",
      "and abnormal detection Lopez et al 2015 \n",
      "Like  most  machine  learning  problems  of  this  nature \n",
      "many  algorithms  have  been  applied  including  time–\n",
      "frequency  analysis  methods  Gotman  et  al  1982  and \n",
      "nonlinear  techniques  Schad  et  al  2008  Despite  much \n",
      "research progress commercially available automated EEG \n",
      "analysis systems are impractical due to high false detection \n",
      "rates  Ramgopal  2014  Servicing  false  alarms  in  critical \n",
      "care  settings  places  too  much  of  a  cognitive  burden  on \n",
      "caregivers and hence the outputs from these systems are \n",
      "ignored  Christensen  et  al  2014  This  creates  quality  of \n",
      "healthcare issues as well as cost and efficiency challenges \n",
      "for  automatic \n",
      "interpretation  of  EEGs  have  employed  modern  machine \n",
      "learning  approaches  Alotaiby  et  al  2014  deep  learning \n",
      "algorithms that employ high dimensional models have not \n",
      "previously been utilized because there has been a lack of big \n",
      "data  resources A significant  resource  Golmohammadi  et \n",
      "al 2017 known as the TUH EEG Seizure Corpus TUSZ \n",
      "has  recently  become  available  for  EEG  interpretation \n",
      "creating a unique opportunity to advance technology \n",
      "Although  contemporary  approaches \n",
      "The  goal  of  this  work  is  to  demonstrate  that  advanced \n",
      "deep learning approaches that have been successful in tasks \n",
      "like image processing and speech recognition where ample \n",
      "amounts  of  annotated  training  data  are  available  can  be \n",
      "applied  to  EEG  interpretation  To  achieve  this  goal  we \n",
      "evaluated several on a standard seizure detection task We \n",
      "propose a novel deep learning architecture that reduces the \n",
      "false  alarm \n",
      "rate  while  maintaining  sensitivity  and \n",
      "specificity  We  demonstrate  that  the  performance  of  this \n",
      "system is now approaching clinical acceptance \n",
      "\n"
     ]
    }
   ],
   "source": [
    "p.open()\n",
    "print(p.contents(maxpages=1, split=False, clean=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... name: ../example/2017-Golmohammadi-arXiv.pdf \n",
      "new name: ../example/2017-Golmohammadi-arXiv.pdf\n",
      "Do you really want to change? (Yes/No)n\n"
     ]
    }
   ],
   "source": [
    "p.rename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-Golmohammadi-arXiv.pdf\n",
      "('/CoreData/git_repos/py_readpaper/example', '2017-Golmohammadi-arXiv.pdf')\n",
      "/CoreData/git_repos/py_readpaper/example/2017-Golmohammadi-arXiv.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "ap = os.path.abspath(\"../example/2017-Golmohammadi-arXiv.pdf\")\n",
    "print(os.path.basename(\"../example/2017-Golmohammadi-arXiv.pdf\"))\n",
    "print(os.path.split(ap))\n",
    "print(os.path.abspath(\"../example/2017-Golmohammadi-arXiv.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n \\n\\nDeep Architectures for  \\n\\nAutomated Seizure Detection in Scalp EEGs  \\n\\n \\n \\n \\n \\n \\n \\n\\nAbstract \\n\\nor \\n\\n(e.g., \\n\\nusing \\n\\nbenign \\n\\nseizure \\n\\nvariants \\n\\ndetection \\n\\nAutomated \\nclinical \\nelectroencephalograms  is  a  challenging  machine  learning \\nproblem  because  the  multichannel  signal  often  has  an \\nextremely low signal to noise ratio. Events of interest such as \\nseizures  are  easily  confused  with  signal  artifacts  (e.g,  eye \\nmovements) \\nslowing). \\nCommercially  available  systems  suffer  from  unacceptably \\nhigh false alarm rates. Deep learning algorithms that employ \\nhigh dimensional models have not previously been effective \\ndue to the lack of big data resources. In this paper, we use the \\nTUH  EEG  Seizure  Corpus  to  evaluate  a  variety  of  hybrid \\ndeep  structures  including  Convolutional  Neural  Networks \\nand  Long  Short-Term  Memory  Networks.  We  introduce  a \\nnovel recurrent convolutional architecture that delivers 30% \\nsensitivity  at  7  false  alarms  per  24  hours.  We  have  also \\nevaluated our system on a held-out evaluation set based on \\nthe  Duke  University  Seizure  Corpus  and  demonstrate  that \\nperformance  trends  are  similar  to  the  TUH  EEG  Seizure \\nCorpus. This is a significant finding because the Duke corpus \\nwas collected with different instrumentation and at different \\nhospitals. Our work shows that deep learning architectures \\nthat  integrate  spatial  and  temporal  contexts  are  critical  to \\nachieving state of the art performance and will enable a new \\ngeneration of clinically-acceptable technology. \\n\\n Introduction   \\n\\nElectroencephalograms (EEGs) are used in a wide range of \\nclinical settings to record electrical activity along the scalp. \\nScalp  EEGs  are  the  primary  means  by  which  physicians \\ndiagnose  brain-related  illnesses  such  as  epilepsy  and \\nseizures (Obeid  and  Picone  2017).  However,  manual \\nanalysis  of  EEG  signals  requires  a  highly  trained  board-\\ncertified neurophysiologist, and is a process that is known to \\nhave relatively low inter-rater agreement (IRA) (Swisher et \\nal.  2015).  It  is  a  time-consuming  and  expensive  process \\nsince the volume and velocity of the data  far exceeds the \\navailable resources for detailed interpretation in real time. \\nAutomated analysis can improve the quality of patient care \\n                                                 \\n \\n\\nby  reducing  manual  error  and  latency.  In  this  paper,  we \\nfocus on the specific problem of seizure detection, though \\nthe  work  presented  here  is  also  applicable  to  other  EEG \\nproblems such as signal event detection (Harati et al. 2016) \\nand abnormal detection (Lopez et al. 2015). \\n\\nLike  most  machine  learning  problems  of  this  nature, \\nmany  algorithms  have  been  applied  including  time–\\nfrequency  analysis  methods  (Gotman  et  al.  1982)  and \\nnonlinear  techniques  (Schad  et  al.  2008).  Despite  much \\nresearch progress, commercially available automated EEG \\nanalysis systems are impractical due to high false detection \\nrates  (Ramgopal  2014).  Servicing  false  alarms  in  critical \\ncare  settings  places  too  much  of  a  cognitive  burden  on \\ncaregivers, and hence, the outputs from these systems are \\nignored  (Christensen  et  al.  2014).  This  creates  quality  of \\nhealthcare issues as well as cost and efficiency challenges. \\nfor  automatic \\ninterpretation  of  EEGs  have  employed  modern  machine \\nlearning  approaches  (Alotaiby  et  al.  2014),  deep  learning \\nalgorithms that employ high dimensional models have not \\npreviously been utilized because there has been a lack of big \\ndata  resources. A significant  resource  (Golmohammadi  et \\nal. 2017), known as the TUH EEG Seizure Corpus (TUSZ), \\nhas  recently  become  available  for  EEG  interpretation \\ncreating a unique opportunity to advance technology. \\n\\nAlthough  contemporary  approaches \\n\\nThe  goal  of  this  work  is  to  demonstrate  that  advanced \\ndeep learning approaches that have been successful in tasks \\nlike image processing and speech recognition, where ample \\namounts  of  annotated  training  data  are  available,  can  be \\napplied  to  EEG  interpretation.  To  achieve  this  goal,  we \\nevaluated several on a standard seizure detection task. We \\npropose a novel deep learning architecture that reduces the \\nfalse  alarm \\nrate  while  maintaining  sensitivity  and \\nspecificity.  We  demonstrate  that  the  performance  of  this \\nsystem is now approaching clinical acceptance. \\n\\n\\x0cExploiting Spatio-Temporal Context \\n\\nSpatial and temporal context are required for accurate dis-\\nambiguation of  seizures from  artifacts  (Obeid  and  Picone \\n2017). In Figure 1, we show our generic architecture for pro-\\ncessing EEG signals. The multichannel signal is sampled at \\n250 Hz using 16 bits of resolution, converted to a feature-\\nbased representation, processed through a sequential mod-\\neler,  and  then  postprocessed  using  a  variety  of  statistical \\nmodels that impose constraints based on subject matter ex-\\npertise. Several architectures that implement Gaussian Mix-\\nture Models (GMMs), hidden Markov model (HMMs) and \\ndeep learning (DL) have been evaluated. \\n\\nFeature extraction, which is not the primary focus of this \\npaper, typically relies on time frequency representations of \\nthe signal. Though we can replace traditional model-based \\nfeature extraction with deep learning-based approaches that \\noperate directly on the sampled data, in this work we focus \\non  the  use  of  traditional  cepstral-based  features  (Picone \\n1993).  The  use  of  more  advanced  discriminative  features \\n(Zhang  et  al.  2016)  has  not  yet  produced  substantial \\nimprovements  in  performance  for  this  application.  Our \\nsystem uses a standard linear frequency cepstral coefficient-\\nbased  feature  extraction  approach  (LFCCs)  (Harati  2015; \\nLopez 2016). We also use first and second derivatives of the \\nfeatures since these improve performance.  \\n\\nNeurologists typically review EEGs in 10 sec  windows \\nand identify events with a resolution of approximately 1 sec. \\nWe analyze the signal in 1 sec epochs, and further divide \\nthis interval into 10 frames of 0.1 secs each so that features \\nare computed every 0.1 seconds (referred to as the frame du-\\nration) using 0.2 second analysis windows (referred to as the \\nwindow duration). The output of our feature extraction pro-\\ncess is a feature vector of dimension 26 for each of 22 chan-\\nnels, with a frame duration of 0.1 secs. \\n\\nSequential Decoding Using HMMs \\nHMMs  are among  the  most  powerful  statistical  modeling \\ntools available today for signals that have both a time and \\nfrequency domain component (Picone 1990). HMMs have \\nbeen  used  extensively  in  sequential  decoding  tasks  like \\nspeech recognition to model the temporal evolution of the \\nsignal. Automated interpretation of EEGs is a problem like \\nspeech recognition since both time domain (e.g., spikes) and \\nfrequency domain information (e.g., alpha waves) are used \\nto identify critical events (Obeid and Picone 2017).  \\n\\nIn this study, a left-to-right channel-independent GMM-\\nHMM,  as  illustrated  in  Figure  1,  was  used  as  a  baseline \\nsystem  for  sequential  decoding.  HMMs  are  attractive \\nbecause  training  is  much  faster  than  comparable  deep \\nlearning systems, and HMMs tend to work well when ample \\namounts  of  annotated  data  are  available.  We  divide  each \\nchannel  of  an  EEG  into  1-second  epochs,  and  further \\nsubdivide  these  epochs  into  a  sequence  of  frames.  Each \\nepoch is classified using an HMM trained on the subdivided \\nepoch,  and \\nthese  epoch-based  decisions  are \\npostprocessed by additional statistical models in a process \\nthat parallels the language modeling component of a speech \\nrecognizer. Standard three state left-to-right HMMs (Picone \\n1990) with 8 Gaussian mixture components per state were \\nused  to  model  each  channel  of  the  22-channel  signal.  A \\ndiagonal covariance matrix assumption was used for each \\nmixture  component.  Channel-independent  models  were \\ntrained since channel-dependent models did not provide any \\nimprovement in performance.  \\n\\nSupervised \\n\\ntraining  based  on \\n\\nthe  Baum-Welch \\nreestimation  algorithm  was  used  to  train  two  models  – \\nseizure and background. Models were trained on segments \\nof data containing seizures based on manual annotations that \\nare  available  as  part  of  TUSZ.  Since  seizures  comprise  a \\n\\nthen \\n\\nFigure 1: A hybrid architecture for automatic interpretation of EEGs that integrates temporal and spatial context for sequential decoding \\n\\nof EEG events is shown. Two levels of postprocessing are used. \\n\\n \\n\\n\\x0csmall percentage of the overall data (3% in the training set; \\n8% in the evaluation set), the amount of non-seizure data \\nwas limited to be comparable to the amount of seizure data, \\nand non-seizure data was selected to include a rich variety \\nof  artifacts  such  as  muscle  and  eye  movements.  Twenty \\niterations of Baum-Welch were used though performance is \\nnot very sensitive to this value. Standard Viterbi decoding \\n(no  beam search)  was  used in recognition  to estimate  the \\nmodel likelihoods for every epoch of data (the entire file was \\nnot  decoded  as  one  stream  because  of  the  imbalance \\nbetween the seizure and background classes – decoding was \\nrestarted for each epoch). \\n\\nThe  output  of  the  epoch-based  decisions  was  postpro-\\ncessed by a deep learning system. Our baseline system used \\na  Stacked  denoising  Autoencoder  (SdA)  (Vincent  et  al. \\n2008) as shown in Figure 1. SdAs are an extension of the \\nstacked autoencoders and are a class of deep learning algo-\\nrithms  well-suited  to  learning  knowledge  representations \\nthat are organized hierarchically (Bengio et al. 2007). They \\nalso  lend  themselves  to  problems  involving  training  data \\nthat  is  sparse,  ambiguous  or  incomplete.  Since  inter-rater \\nagreement is relatively low for seizure detection (Swisher et \\nal. 2015), it made sense to evaluate this type of algorithm as \\npart of a baseline approach. \\n\\nAn N-channel EEG was transformed into N independent \\nfeature streams using a standard sliding window based ap-\\nproach. The hypotheses generated by the HMMs were post-\\nprocessed using a second stage of processing that examines \\nthe temporal and spatial context. We apply a third pass of \\npostprocessing  that  uses  a  stochastic  language  model  to \\nsmooth hypotheses involving sequences of events so that we \\ncan suppress spurious outputs. This third stage of postpro-\\ncessing provides a moderate reduction in false alarms. \\n\\nTraining of SdA networks are done in two steps: (1) pre-\\ntraining in a greedy layer-wise approach (Bengio et al. 2007) \\nand (2) fine-tuning by adding a logistic regression layer on \\ntop of the network (Hinton et al. 2006). The output of the \\nfirst stage of processing is a vector of two likelihoods for \\neach  channel  at  each  epoch.  Therefore,  if  we  have  22 \\nchannels,  which  is  typical  for  an  EEG  collected  using  a \\nstandard 10/20 configuration (Obeid and Picone 2016), and \\n2 classes (seizure and background), we will have a vector of \\ndimension 2 x 22 = 44 for each epoch. \\n\\nEach of these scores is independent of the spatial context \\n(other  EEG  channels)  or  temporal  context  (past  or  future \\nepochs).  To  incorporate  context,  we  form  a  supervector \\nconsisting  of  N  epochs  in  time  using  a  sliding  window \\napproach. We find benefit to making N large – typically 41. \\nThis results in a vector of dimension 1,804 that needs to be \\nprocessed each epoch. The input dimensionality is too high \\nconsidering the amount of manually labeled data available \\nfor  training  and  the  computational  requirements.  To  deal \\nwith this problem we used Principal Components Analysis \\n\\n(PCA) (Ross et al. 2008) to reduce the dimensionality to 20 \\nbefore applying the SdA postprocessing. \\n\\nThe parameters of the SdA model are optimized to mini-\\nmize the average reconstruction error using a cross-entropy \\nloss function. In the optimization process, a variant of sto-\\nchastic gradient descent is used called “Minibatch stochastic \\ngradient descent” (MSGD) (Zinkevich et al. 2010). MSGD \\nworks identically to stochastic gradient descent, except that \\nwe use more than one training example to make each esti-\\nmate of the gradient. This technique reduces variance in the \\nestimate of the gradient, and often makes better use of the \\nhierarchical memory organization in modern computers. \\n\\nThe SdA network has three hidden layers with corruption \\nlevels of 0.3 for each layer. The number of nodes per layer \\nare: first layer = 800, second layer = 500, third layer = 300. \\nThe  parameters  for  pre-training  are:  learning  rate  =  0.5, \\nnumber of epochs = 150, batch size = 300. The parameters \\nfor fine-tuning are: learning rate = 0.1, number of epochs = \\n300, batch size = 100. The overall result of the second stage \\nis a probability vector of dimension two containing a likeli-\\nhood that each label could have occurred in the epoch. A \\nsoft decision paradigm is used rather than a hard decision \\nparadigm because this output is smoothed in the third stage \\nof processing. A more detailed explanation about the third \\npass of processing is presented in (Harati et al. 2016). \\n\\nLike \\n\\nContext Modeling Using LSTMs \\nTo improve our ability to model context, a hybrid system \\ncomposed  of  an  HMM  and  a  Long  Short  Term  Memory \\n(LSTM) network (Hochreiter et al. 1997) was implemented. \\nThese  networks  are  a  special  kind  of  recurrent  neural \\nnetwork (RNN) architecture that is capable of learning long-\\nterm dependencies, and can bridge time intervals exceeding \\n1,000 steps even for noisy incompressible input sequences. \\nThis is  achieved  by  multiplicative  gate  units  that  learn to \\nopen and close access to the constant error flow. \\n\\nthe  HMM/SdA  hybrid  approach  previously \\ndescribed,  the  output  of  the  first  pass  is  a  vector  of \\ndimension 2 × 22 × the window length. Therefore, we also \\nuse PCA before LSTM to reduce the dimensionality of the \\ndata to 20. For this study, we used a window length of 41 \\nfor LSTM, and this layer is composed of one hidden layer \\nwith 32 nodes. The output layer nodes in this LSTM level \\nuse a sigmoid function. The parameters of the models are \\noptimized to minimize the error using a cross-entropy loss \\nfunction.  Adaptive  Moment  Estimation  (Adam)  is  used \\n(Kingma et al. 2015) in the optimization process. \\n\\nTo explore the potential of LSTMs to encode long-term \\ndependencies,  we  designed  another  architecture,  where \\nIncremental  Principal  Components  Analysis  (IPCA)  was \\nused for dimensionality reduction (Ross et al. 2008; Levy et \\nal.  2000).  LSTM  networks  which  operate  directly  on \\nfeatures spanning long periods of time need more memory \\n\\n\\x0cefficient  approaches. \\nIPCA  has  constant  memory \\ncomplexity, on the order of the batch size, enabling use of a \\nlarge dataset without loading the entire dataset into memory. \\nIPCA  builds  a  low-rank  approximation  for  the  input  data \\nusing  an  amount  of  memory  which  is  independent  of  the \\nnumber of input data samples. It is still dependent on the \\ninput data features, but changing the batch size allows for \\ncontrol of memory usage. \\n\\nThe architecture of our IPCA/LSTM system is presented \\nin  Figure  2.  In  the  IPCA/LSTM  system,  samples  are \\nconverted  to  features  by  our  standard  feature  extraction \\nmethod  previously  described.  Next,  the  features  are \\ndelivered to an IPCA layer for spatial context analysis and \\ndimensionality reduction. The output of IPCA is delivered \\nto a one-layer LSTM for classification. The input to IPCA \\nhas a dimension that is a  multiplication of the number of \\nchannels, the feature vector length, the number of features \\nper seconds and window duration (in seconds). We typically \\nuse  a  7-second  window  duration,  so  the  IPCA  input  is  a \\nvector of dimension 22 × 26 × 7 × 10 = 4004. A batch size \\nof 50 is used in IPCA and the output dimension is 25. In \\norder to learn long-term  dependencies, one  LSTM  with  a \\nhidden layer size of 128 and batch size of 128 is used along \\nwith Adam optimization and a cross–entropy loss function. \\nTwo-Dimensional Decoding Using CNNs \\nConvolutional  Neural  Networks  (CNNs)  have  delivered \\nstate of the art performance on highly challenging tasks such \\nas  speech  (Saon  et  al.  2016)  and  image  recognition \\n(Simonyan  et  al.  2014).  CNNs  are  usually  comprised  of \\nconvolutional layers along with subsampling layers which \\nare followed by one or more fully connected layers. In the \\ncase of two dimensional CNNs that are common in image \\nand speech recognition, the input to a convolutional layer is \\nW × H × N data (e.g. an image) where W and H are the width \\nand height of the input data, and N is the number of channels \\n(e.g. in an RGB image, N = 3). The convolutional layer will \\nhave K filters (or kernels) of size M × N × Q where M and \\nN  are  smaller  than  the  dimension  of  the  data  and  Q  is \\ntypically smaller than the number of channels. In this way \\nCNNs have a large learning capacity that can be controlled \\n\\nby  varying  their  depth  and  breadth  to  produce  K  feature \\nmaps  of  size  (W-M+1)  ×  (H-N+1).  Each  map  is  then \\nsubsampled  with  max  pooling  over  P × P  contiguous \\nregions. An additive nonlinearity is applied to each feature \\nmap either before or after the subsampling layer. \\n\\nOur overall architecture of a system that combines CNN \\nand a multi-layer perceptron (MLP) (Simonyan et al. 2014) \\nis  shown \\nin  Figure 3.  The  network  contains  six \\nconvolutional  layers,  three  max  pooling  layers  and  two \\nfully-connected layers. A rectified linear unit (ReLU) non-\\nlinearity is applied to the output of every convolutional and \\nfully-connected  layer  (Nair  et  al.  2010).  Drawing  on  an \\nimage classification analogy, each image is a signal where \\nthe width of the image (W) is the window length multiplied \\nby  the  number  of  samples  per  second,  the  height  of  the \\nimage (H) is the number of EEG channels and the number \\nof image channels (N) is the length of the feature vector. \\n\\nIn our optimized system, a window duration of 7 seconds \\nis used. The first convolutional layer filters the input of size \\nof 70 × 22 × 26 using 16 kernels of size 3 × 3 with a stride \\nof 1. The second convolutional layer filters its input using \\n16 kernels of size 3 × 3 with a stride of 1. The first max \\npooling layer takes as input the output of the second convo-\\nlutional layer and applies a pooling size of 2 × 2. This pro-\\ncess  is  repeated  two  times  more  with  32  and  64  kernels. \\nNext, a fully-connected layer with 512 neurons is applied \\nand the output is fed to a 2-way sigmoid function which pro-\\nduces a two-class decision (the final epoch label). \\nRecurrent Convolutional Neural Networks \\nIn our final architecture, which is shown in Figure 4, we in-\\ntegrate 2D CNNs, 1-D CNNs and LSTM networks, which \\nwe refer to as a CNN/LSTM, to better exploit long-term de-\\npendencies.  Note  that  the  way  that  we  handle  data  in \\nCNN/LSTM  is  different  from the  CNN/MLP  system  pre-\\nsented in Figure 3. Drawing on a video classification anal-\\nogy, input data is composed of frames distributed in time \\nwhere  each  frame  is  an  image  of  width  (W)  equal  to  the \\nlength of a feature vector, the height (H) equals the number \\nof  EEG  channels, and  the  number of image channels  (N) \\nequals one. Then input data consists of T frames where T is \\n\\n \\nFigure 2: An architecture that integrates IPCA for spatial context analysis and LSTM for learning long-term temporal dependencies  \\n\\n\\x0cFigure 3: Two-dimensional decoding of EEG signals using a CNN/MLP hybrid architecture is shown that consists of six convolutional \\n\\nlayers, three max pooling layers and two fully-connected layers. \\n\\n \\n\\n \\n\\nFigure 4: A deep recurrent convolutional architecture for two-dimensional decoding of EEG signals that integrates 2D CNNs, 1-D CNNs \\n\\nand LSTM networks is shown. \\n\\nequal  to  the  window  length  multiplied  by  the  number  of \\nsamples per second. In our optimized system with a window \\nduration of 21 seconds, the first 2D convolutional layer fil-\\nters 210 frames (T = 21 × 10) of EEGs distributed in time \\nwith a size of 26 × 22 × 1 (W = 26, H = 22, N = 1) using 16 \\nkernels of size 3 × 3 and with a stride of 1. The first 2D max \\npooling layer takes as input a vector which is 260 frames \\ndistributed in time with a size of 26 × 22 × 16 and applies a \\npooling size of 2 × 2. This process is repeated two times with \\n\\ntwo 2D convolutional layers with 32 and 64 kernels of size \\n3 × 3 respectively and two 2D max pooling layers with a \\npooling size 2 × 2. \\n\\nThe output of third max pooling is flattened to 210 frames \\nwith size of 384 × 1. Then a 1D convolutional layer filters \\nthe output of the flattening layer using 16 kernels of size 3 \\nwhich decreases the dimensionality in space to 210 × 16. \\nThen we apply a 1D maxpooling layer with a size of 8 to \\ndecrease the dimensionality to 26 × 16. This is the input to \\n\\n\\x0ca deep bidirectional LSTM network where the dimensional-\\nity of the output space is 128 and 256. The output of the last \\nbidirectional LSTM layer is fed to a 2-way sigmoid function \\nwhich produces a final classification of an epoch. To over-\\ncome  the  problem  of  overfitting  and  force  the  system  to \\nlearn more robust features, dropout and Gaussian noise lay-\\ners are used between layers (Srivastava et al. 2010). To in-\\ncrease  non-linearity,  Exponential  Linear  Units  (ELU)  are \\nused (Clevert et al. 2017). Adam is used in the optimization \\nprocess along with a mean squared error loss function.  \\n\\nExperiments \\n\\nThe  lack  of  big  data  resources  that  can  be  used  to  train \\nsophisticated statistical models compounds a major problem  \\nin automatic seizure detection. Inter-rater agreement for this \\ntask is low, especially when considering short seizure events \\n(Obeid  and  Picone  2017).  Manual  annotation  of  a  large \\namount  of  data  by  a  team  of  certified  neurologists  is \\nextremely expensive and time consuming. In this study, we \\nare reporting results for the first time on the TUSZ and a \\ncomparable corpus, DUSZ, from Duke University (Swisher \\net  al,  2015).  TUSZ  was  used  as  the  training  and  test  set \\ncorpus, while DUSZ was used as a held-out evaluation set. \\nIt is important to note that TUSZ was collected using several \\ngenerations  of  Natus  EEG  equipment,  while  DUSZ  was \\ncollected using Nihon Kohden equipment. Hence, this is a \\ntrue open-set evaluation since the data were collected under \\ncompletely  different  recording  conditions.  A  summary  of \\nthese corpora is shown in Table 1. \\n\\nA  comparison  of  the  performance  of  the  different \\narchitectures presented in this paper, for sensitivity in range \\nof  30%,  are  shown  in  Table 2.  The  related  DET  curve  is \\nillustrated in Figure 5. These systems were evaluated using \\na method of scoring popular in the EEG research community \\nknown  as  the  overlap  method  (Wilson  et  al.  2003).  True \\npositives (TP) are defined as the number of epochs identified \\nas  a  seizure  in  the  reference  annotations  and  correctly \\nlabeled as a seizure by the system. True negatives (TN) are \\ndefined as the number of epochs correctly identified as non-\\nseizures. False positives (FP) are defined as the number of \\nepochs incorrectly labeled as seizure while false negatives \\n(FN) are defined as the number of epochs incorrectly labeled \\n\\nTable 1: An overview of the TUHS and Duke corpora \\nDuke \\nEval \\n\\nDescription \\n\\nTUHS \\n\\nEval \\n\\nTrain \\n64 \\n281 \\n1,028 \\n17,686 \\n\\n50 \\nPatients \\n229 \\nSessions \\n985 \\nFiles \\nSeizure (secs) \\n45,649 \\nNon-Seizure (secs)  596,696  556,033 \\n614,382  601,682 \\nTotal (secs) \\n\\n45 \\n45 \\n45 \\n48,567 \\n599,381 \\n647,948 \\n\\n \\n\\nTable 2: Performance on the TUSZ \\n\\nSystem \\n\\nHMM \\nHMM/SdA \\nHMM/LSTM \\nIPCA/LSTM \\nCNN/MLP \\nCNN/LSTM \\n\\n \\n\\nSensitivity  Specificity  FA/24 Hrs. \\n244 \\n77 \\n60 \\n73 \\n77 \\n7 \\n\\n30.32% \\n35.35% \\n30.05% \\n32.97% \\n39.09% \\n30.83% \\n\\n80.07% \\n73.35% \\n80.53% \\n77.57% \\n76.84% \\n96.86% \\n\\nFigure 5: A DET curve comparing performance on TUSZ \\n\\n \\n\\nas non-seizure. Sensitivity shown in Table 2 is computed as \\nTP/(TP+FN). Specificity is computed as TN/(TN+FP). The \\nfalse alarm rate is the number of FPs per 24 hours.  \\n\\nIt is important to note that the results are much lower than \\nwhat  is  often  published  in  the  literature  on  other  seizure \\ndetection  tasks.  This  is  due  to  a  combination  of  factors \\nincluding  (1)  the  neuroscience  community  has  favored  a \\nmore permissive  method of  scoring that  tends to  produce \\nmuch higher sensitivities and lower false alarm rates; and \\n(2)  TUSZ  is  a  much  more  difficult  task  than  any  corpus \\npreviously released as open source. The evaluation set was \\ndesigned to be representative of common clinical issues and \\nincludes many challenging examples of seizures. \\n\\nAlso, note that the HMM baseline system, which is shown \\nin  the  first  row  of  Table 2,  operates  on  each  channel \\nindependently.  The  other  methods  consider  all  channels \\nsimultaneously  by  using  a  supervector \\nis  a \\nconcatenation  of  the  feature  vectors  for  all  channels.  The \\nbaseline  HMM  system  only  classifies  epochs  (1  sec  in \\nduration) using data from within that epoch. It does not look \\nacross channels or across multiple epochs when performing \\nepoch-level classification. The results of the hybrid HMM \\nand  deep  learning  structures  show  that  adding  a  deep \\nlearning structure for temporal and spatial analysis of EEGs \\ncan decrease the false alarm rate dramatically. Further, by \\ncomparing the results of HMM/SdA with HMM/LSTM, we \\nfind that a simple one layer LSTM performs better than 3 \\nlayers  of  SdA  due  to  LSTM’s  ability  to  explicitly  model \\nlong-term  dependencies.  Note \\nthe \\ncomplexity  and  training  time  of  these  two  systems  is \\ncomparable. \\n\\nthis  case \\n\\nthat \\n\\nthat \\n\\nin \\n\\n\\x0cis \\n\\nthe \\n\\nThe best overall system is the combination of CNN and \\nLSTM. This doubly deep recurrent convolutional structure \\nmodels  both  spatial  relationships  (e.g.,  cross-channel \\ndependencies)  and  temporal  dynamics  (e.g.,  spikes).  For \\nexample,  CNN/LSTM  does  a  much  better  job  rejecting \\nartifacts that are easily confused with spikes because these \\nappear on only a few channels, and hence can be filtered \\nbased on correlations between channels. The depth of the \\nconvolutional  network \\ntop \\nconvolutional layers tend to learn generic features while the \\ndeeper  layers  learn  dataset  specific  features.  Performance \\ndegrades  if  a  single  convolutional  layer  is  removed.  For \\nexample, removing any of the middle convolutional layers \\nresults in a loss of about 4% in the sensitivity. \\n\\nimportant  since \\n\\nWe have also conducted an evaluation of our CNN/LSTM \\nsystem  on  a  DUSZ.  The  results  are  shown  in  Table 3.  A \\nDET curve is shown in Figure 5. At high false positive rates, \\nperformance  between  the  two  systems  is  comparable.  At \\nlow false positive rates, false positives on TUSZ are lower \\nthan on DUSZ. This suggests there is room for additional \\noptimizations on DUSZ. \\n\\nIn these experiments, we observed that the choice of op-\\ntimization  method  had  a  considerable  impact  on  perfor-\\nmance.  The  results  of  our  best  performing  system, \\nCNN/LSTM, was evaluated using a variety of optimization \\nmethods,  including  SGD  (Wilson  et  al.  2003),  RMSprop \\n(Bottou  et  al.  2004),  Adagrad  (Tieleman  et  al.  2012), \\nAdadelta (Duchi et al. 2011), Adam (Kingma et al. 2015), \\nAdamax  (Kingma  et  al.  2015)  and  Nadam  (Zeiler  et  al. \\n2013)  as  shown  in  Table  4.  The  best  performance  is \\n\\nachieved with Adam, a learning rate of 𝛼=0.0005, a learn-\\ning rate decay of 0.0001, exponential decay rates of 𝛽(cid:2869)=\\n0.9 and 𝛽(cid:2870)=0.999 for  the  moment  estimates  and  a  fuzz \\nfactor of 𝜖=10(cid:2879)(cid:2876). The parameters follow the notation de-\\n\\nscribed in (Kingma et al. 2015). Table 4 also illustrates that \\nNadam delivers comparable performance to Adam. Adam \\ncombines  the  advantages  of  AdaGrad  which  works  well \\n\\nTable 3: Performance of CNN/LSTM on DUSZ \\n\\nCorpus \\n\\nTUSZ \\nDUSZ \\n\\nSensitivity  Specificity  FA/24 Hrs. \\n7 \\n40 \\n\\n30.83% \\n33.71% \\n\\n96.86% \\n70.72% \\n\\nwith sparse gradients, and RMSProp which works well in \\nnon-stationary settings. \\n\\nSimilarly, we evaluated our CNN/LSTM using different \\nactivation functions, as shown in Table 5. ELU delivers a \\nsmall but measurable increase in sensitivity, and more im-\\nportantly, a reduction in false alarms. ReLUs and ELUs ac-\\ncelerate learning by decreasing the gap between the normal \\ngradient and the unit natural gradient (Clevert et al. 2017). \\nELUs push the mean towards zero but with a significantly \\nsmaller  computations  footprint.  But  unlike  ReLUs,  ELUs \\nhave a clear saturation plateau in its negative regime, allow-\\ning them to learn a more robust and stable representation, \\nand making it easier to model dependencies between ELUs. \\n\\nConclusions \\n\\nIn this paper, we introduced a variety of deep learning archi-\\ntectures for automatic classification of EEGs including a hy-\\nbrid architecture that integrates CNN and LSTM. While this \\narchitecture  delivers  better  performance  than  other  deep \\nstructures, its performance still does not meet the needs of \\nclinicians.  Human  performance  on  similar  tasks  is  in  the \\nrange of 65% sensitivity with a false alarm rate of 12 per 24 \\nhours (Swisher et al. 2015). The false alarm rate is particu-\\nlarly important to critical care applications since it impacts \\nthe workload experienced by healthcare providers. \\n\\nThe primary error modalities observed were false alarms \\ngenerated during brief delta range slowing patterns such as \\nintermittent rhythmic delta activity. A variety of these types \\nof artifacts have been observed mostly during inter-ictal and \\npost-ictal stages. Training models on such events with di-\\nverse morphologies has the potential to significantly reduce \\nthe remaining false alarms. This is one reason we are con-\\ntinuing our efforts to annotate a larger portion of TUSZ. \\n\\nTable 4: Comparison of optimization algorithms \\nOpt. \\n\\nSGD \\nRMSprop  \\nAdagrad \\nAdadelta \\nAdam \\nAdamax \\nNadam \\n\\nSensitivity  Specificity  FA/24 Hrs. \\n44 \\n23 \\n31 \\n33 \\n7 \\n18 \\n14 \\n\\n23.12% \\n25.17% \\n26.42% \\n26.11% \\n30.83% \\n29.25% \\n30.27% \\n\\n72.24% \\n83.39% \\n80.42% \\n79.14% \\n96.86% \\n89.64% \\n92.17% \\n\\nFigure 6: A performance comparison of TUSZ and DUSZ \\n\\n \\n\\n \\n\\nTable 5: Comparison of activation functions \\n\\nActivation  Sensitivity  Specificity  FA/24 Hrs. \\nLinear \\n25 \\n21 \\nTanh \\n19 \\nSigmoid \\n18 \\nSoftsign \\nReLU \\n11 \\n7 \\nELU \\n\\n26.46% \\n26.53% \\n28.63% \\n30.05% \\n30.51% \\n30.83% \\n\\n88.48% \\n89.17% \\n90.08% \\n90.51% \\n94.74% \\n96.86% \\n\\n\\x0cObeid, I., and Picone, J. 2017. Machine Learning Approaches to \\nAutomatic Interpretation of EEGs. In E. Sejdik & T. Falk (Eds.), \\nBiomedical Signal Processing in Big Data (1st ed., p. N/A). Boca \\nRaton, Florida, USA: CRC Press.  \\nPicone,  J.  1990.  Continuous  Speech  Recognition  Using  Hidden \\nMarkov Models. IEEE ASSP Magazine, 7(3), 26–41. \\nPicone, J. 1993. Signal modeling techniques in speech recognition. \\nProceedings of the IEEE, 81(9), 1215–1247. \\nRamgopal,  S.  2014.  Seizure  detection,  seizure  prediction,  and \\nclosed-loop warning systems in epilepsy. Epilepsy & Behavior, 37, \\n291–307. \\nRoss, D. A., Lim, J., Lin, R. S., & Yang, M. H. 2008. Incremental \\nlearning for robust visual tracking. International Journal of Com-\\nputer Vision, 77(1–3), 125–141. \\nSaon, G., Sercu, T., Rennie, S., & Kuo, H. K. J. 2016. The IBM \\n2016 English conversational telephone speech recognition system. \\nIn Proceedings of INTERSPEECH, pp. 7–11. \\nSchad, A., et al. 2008. Application of a multivariate seizure detec-\\ntion and prediction method to non-invasive and intracranial long-\\nterm EEG recordings. Clinical Neurophysiology, 119(1), 197–211. \\nSimonyan, K., & Zisserman, A. 2014. Very Deep Convolutional \\nNetworks  for  Large-Scale  Image  Recognition.  arXiv  preprint \\narXiv:1409.1556. \\nSrivastava,  N.,  et  al.  2014.  Dropout:  A  Simple  Way  to  Prevent \\nNeural Networks from Overfitting. Journal of Machine Learning \\nResearch, 15, 1929–1958. \\nSwisher, C. B., et al. 2015. Diagnostic Accuracy of Electrographic \\nSeizure Detection by Neurophysiologists and Non-Neurophysiol-\\nogists in the Adult ICU Using a Panel of Quantitative EEG Trends. \\nJournal of Clinical Neurophysiology, 324-330. \\nTieleman, T., & Hinton, G. 2012. Lecture 6.5-rmsprop: Divide the \\ngradient  by  a  running  average  of \\nits  recent  magnitude. \\nCOURSERA: Neural Networks for Machine Learning. \\nVincent, P., Larochelle, H., Bengio, Y., & Manzagol, P.-A. 2008. \\nExtracting and composing robust features with denoising autoen-\\ncoders.  In  Proceedings  of  the  25th  International  Conference on \\nMachine Learning (pp. 1096–1103). New York, NY, USA. \\nWilson, S. B., Scheuer, M. L., Plummer, C., Young, B., & Pacia, \\nS. 2003. Seizure detection: correlation of human experts. Clinical \\nNeurophysiology, 114(11), 2156–2164. \\nZeiler,  M.  D.  2013.  ADADELTA:  An  Adaptive  Learning  Rate \\nMethod. IEEE Signal Processing Letters, 20(12), 1266–1269. \\nZhang, X., Liang, Y., Zheng, Y., An, J., & Jiao, L. C. 2016. Hier-\\narchical Discriminative Feature Learning for Hyperspectral Image \\nClassification. IEEE Geoscience and Remote Sensing Letters. \\nZinkevich, M., Weimer, M., Smola, A., & Li, L. 2010. Parallelized \\nstochastic gradient descent. Advances in Neural Information Pro-\\ncessing Systems. \\n \\n\\nReferences \\n\\nAlotaiby,  T., Alshebeili,  S.,  Alshawi, T.,  Ahmad, I.,  &  Abd El-\\nSamie, F. 2014. EEG seizure detection and prediction algorithms: \\na  survey.  EURASIP  Journal  on  Advances  in  Signal  Processing, \\n2014(1), 1–21. \\nBengio,  Y.,  Lamblin,  P.,  Popovici,  D.,  &  Larochelle,  H.  2007. \\nGreedy layer-wise training of deep networks. In Advances in Neu-\\nral  Information  Processing  System  (pp.  153–160).  Vancouver, \\nB.C., Canada. \\nBottou,  L.,  &  Lecun,  Y.  2004.  Large  Scale  Online  Learning. \\nAdvances in Neural Information Processing Systems, 217–225. \\nChristensen, M., Dodds, A., Sauer, J., & Watts, N. 2014. Alarm \\nsetting for the  critically  ill patient:  a descriptive pilot  survey  of \\nnurses’ perceptions of current practice in an Australian Regional \\nCritical Care Unit. Intensive and Critical Care Nursing. \\nClevert,  D.,  Unterthiner,  T.,  &  Hochreiter,  S.  2017.  Fast  and \\nAccurate  Deep  Network  Learning  by  Exponential  Linear  Units \\n(ELUs). arXiv preprint arXiv:1511.07289. \\nDuchi,  J.,  Hazan,  E.,  &  Singer,  Y.  2011.  Adaptive  Subgradient \\nMethods  for  Online  Learning  and  Stochastic  Optimization. \\nJournal of Machine Learning Research, 12, 2121–2159. \\nGolmohammadi, M., et al. 2017. The TUH EEG Seizure Corpus. \\nIn Proceedings of the American Clinical Neurophysiology Society \\nAnnual Meeting (p. 1). Phoenix, Arizona, USA: American Clinical \\nNeurophysiology Society. \\nGotman, J. 1982. Automatic recognition of epileptic seizures in the \\nEEG.  Electroencephalography  and  Clinical  Neurophysiology, \\n54(5), 530–540. \\nHarati, A. H., et al. 2016. Automatic Interpretation of EEGs for \\nClinical Decision Support. In American Clinical Neurophysiology \\nSociety (ACNS) Annual Meeting (p. 1). Orlando, Florida, USA. \\nHarati, A., et al. 2015. Improved EEG Event Classification Using \\nDifferential Energy. In Proc. IEEE Signal Processing in Medicine \\nand Biology Symposium (pp. 1–4). Philadelphia, PA, USA. \\nHinton, G. E., Osindero, S., & Teh, Y.-W. 2006. A Fast Learning \\nAlgorithm  for  Deep  Belief  Nets.  Neural  Computation,  18(7), \\n1527–1554. \\nHochreiter, S., & Schmidhuber, J. 1997. Long short-term memory. \\nNeural Computation, 9(8), 1735–80. \\nKingma, D. P., & Ba, J. L. 2015. Adam: a Method for Stochastic \\nOptimization. International Conference on Learning Representa-\\ntions 2015, 1–15. \\nLevy, A., & Lindenbaum, M. 2000. Sequential Karhunen-Loeve \\nbasis extraction and its application to images. IEEE Transactions \\non Image Processing, 9(8), 1371–1374. \\nLopez, S., et al. 2016. An Analysis of Two Common Reference \\nPoints for EEGs. In Proc. of the IEEE Signal Processing in Medi-\\ncine and Biology Symposium (pp. 1–4). Philadelphia, PA, USA. \\nLopez,  S.,  et  al.  2015.  Automated  Identification  of  Abnormal \\nEEGs. In IEEE Signal Processing in Medicine and Biology Sym-\\nposium (pp. 1–4). Philadelphia, PA, USA. \\nNair, V., & Hinton, G. E. 2010. Rectified Linear Units Improve \\nRestricted  Boltzmann  Machines.  Proceedings  of \\nthe  27th \\nInternational Conference on Machine Learning, (3), 807–814. \\nObeid, I., & Picone, J. 2016. The Temple University Hospital EEG \\nData Corpus. Frontiers in Neuroscience, Section Neural Technol-\\nogy, 10, 196. \\n\\n\\x0c'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_readpaper.convertPDF_pdfminer(\"../example/2017-Golmohammadi-arXiv.pdf\", maxpages=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(', ')', '\\\\', '.']\n"
     ]
    }
   ],
   "source": [
    "clean = \"()\\.\"\n",
    "print(list(clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p._exif.setTag('Description', 'Automated seizure detection using clinical electroencephalograms is a challenging machine learning problem because the multichannel signal often has an extremely low signal to noise ratio. Events of interest such as seizures are easily confused with signal artifacts (e.g, eye movements) or benign variants (e.g., slowing). Commercially available systems suffer from unacceptably high false alarm rates. Deep learning algorithms that employ high dimensional models have not previously been effective due to the lack of big data resources. In this paper, we use the TUH EEG Seizure Corpus to evaluate a variety of hybrid deep structures including Convolutional Neural Networks and Long Short-Term Memory Networks. We introduce a novel recurrent convolutional architecture that delivers 30% sensitivity at 7 false alarms per 24 hours. We have also evaluated our system on a held-out evaluation set based on the Duke University Seizure Corpus and demonstrate that performance trends are similar to the TUH EEG Seizure Corpus. This is a significant finding because the Duke corpus was collected with different instrumentation and at different hospitals. Our work shows that deep learning architectures that integrate spatial and temporal contexts are critical to achieving state of the art performance and will enable a new generation of clinically-acceptable technology.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... [set_meta] tag and value are same\n",
      "... [set_meta] tag and value are same\n",
      "... [set_meta] tag and value are same\n",
      "... [set_meta] tag and value are same\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p._exif.setTag('Journal', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
